文本 学习分类文本
有监督分类
    性别鉴定
def gender_features(word):
    return {'last_letter': word[-1]}
gender_features('Shrek')

from nltk.corpus import names
import random
names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])
random.shuffle(names)
选择正确的特征
特征提取通过反复试验和错误的过程建立的，由哪些信息是与问题相关的直觉指引的。它通常以“厨房水槽”的方法开始，
包括你能想到的所有特征，然后检查哪些特征是实际有用的
例 6-1. 一个特征提取器，过拟合性别特征。这个特征提取器返回的特征集包括大量指定的特征，从而导致对于相对较小的名字语料库过拟合
def gender_features2(name):
    features = {}
    features["firstletter"] = name[0].lower()
    features["lastletter"] = name[–1].lower()
    for letter in 'abcdefghijklmnopqrstuvwxyz':
        features["count(%s)" % letter] = name.lower().count(letter)
        features["has(%s)" % letter] = (letter in name.lower())
    return features
gender_features2('John')

def gender_features3(word):
    return {'suffix1': word[-1:], 'suffix2': word[-2:], 'perfix_1': word[:1], "perfix_2": word[:2]}

"""
你要用于一个给定的学习算法的特征的数目是有限的——如果你提供太多的特
征，那么该算法将高度依赖你的训练数据的特，性而一般化到新的例子的效果不会很好。这
个问题被称为过拟合
"""
featuresets = [(gender_features2(n), g) for (n, g) in names]
train_set, test_set = featuresets[500:], featuresets[:500]
classifier = nltk.NaiveBayesClassifier.train(train_set)
print nltk.classify.accuracy(classifier, test_set)

"""
yn 结尾的名字显示以女性为主，尽管事实上，n 结尾的名字往往是男性；以 ch 结尾的名字通常
是男性，尽管以 h 结尾的名字倾向于是女性
"""
train_names = names[1500:]
devtest_names = names[500:1500]
test_names = names[:500]
train_set = [(gender_features3(n), g) for (n, g) in train_names]  # 训练集数据
devtest_set = [(gender_features3(n), g) for (n, g) in devtest_names]  # 开发测试集
test_set = [(gender_features3(n), g) for (n, g) in test_names]  # 测试
classifier = nltk.NaiveBayesClassifier.train(train_set)
print nltk.classify.accuracy(classifier, devtest_set)
errors = []
for (name, tag) in devtest_names:
    guess = classifier.classify(gender_features3(name))
    if guess != tag:
        errors.append((tag, guess, name))
for (tag, guess, name) in sorted(errors):  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    print 'correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name)

"""我们为文档定义一个特征提取器，这样分类器就会知道哪些方面的数据应注意
（见例 6-2）。对于文档主题识别，我们可以为每个词定义一个特性表示该文档是否包含这
个词。为了限制分类器需要处理的特征的数目，我们一开始构建一个整个语料库中前 2000
个最频繁词的链表。然后，定义一个特征提取器，简单地检查这些词是否在一个给定的文档中。
例 6-2. 一个文档分类的特征提取器，其特征表示每个词是否在一个给定的文档中
"""
all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())  # 获取影评中所有数据
word_featrues = all_words.keys()[:2000]


def document_features(document):
    document_words = set(document)
    features = {}
    for word in word_featrues:
        features['contains(%s)' % word] = (word in document_words)
    return features
print document_features(movie_reviews.words('pos/cv957_8737.txt'))


"""
训练和测试一个分类器进行文档分类
"""
featrueset = [(document_features(d), c) for (d, c) in documents]
train_set, test_set = featrueset[200:], featrueset[:200]
classifier = nltk.NaiveBayesClassifier.train(train_set)
print nltk.classify.accuracy(classifier, train_set)
classifier.show_most_informative_features(5)
"""
Most Informative Features
          contains(sans) = True              neg : pos    =      9.0 : 1.0
    contains(mediocrity) = True              neg : pos    =      7.7 : 1.0
   contains(bruckheimer) = True              neg : pos    =      6.4 : 1.0
         contains(wires) = True              neg : pos    =      6.4 : 1.0
         contains(tripe) = True              neg : pos    =      6.4 : 1.0
提到 Seagal 的评论中负面的是正面的大约 8 倍，而提到 Damon 的评论中正面的是负面的大约 6 倍
"""
第 5 章中，我们建立了一个正则表达式标注器，通过查找词内部的组成，为词选择词性
标记。然而，这个正则表达式标注器是手工制作的。作为替代，我们可以训练一个分类器来
算出哪个后缀最有信息量。首先，让我们找出最常见的后缀

suffix_fdist = nltk.FreqDist()
for word in brown.words():
    word = word.lower()
    suffix_fdist[word[-1:]] += 1
    suffix_fdist[word[-2:]] += 1
    suffix_fdist[word[-3:]] += 1
common_suffixes = suffix_fdist.keys()[:100]
print common_suffixes


def pos_features(word):
    """
    定义一个特征提取器函数，检查给定的单词的这些后缀
    :param word:
    :return:
    """
    features = {}
    for suffix in common_suffixes:
        features['endswith(%s)' % suffix] = word.lower().endswith(suffix)
    return features

"""
特征提取函数的行为就像有色眼镜一样，强调我们的数据中的某些属性（颜色），并使
其无法看到其他属性。分类器在决定如何标记输入时，将完全依赖它们强调的属性。在这种
情况下，分类器将只基于一个给定的词拥有（如果有）哪个常见后缀的信息来做决定。
现在，我们已经定义了我们的特征提取器，可以用它来训练一个新的“决策树”的分类
器
"""
# 使用决策树
tagged_word = brown.tagged_words(categories="news")
featuresets = [(pos_features(n), g) for (n, g) in tagged_word]
size = int(len(featuresets) * 0.1)
train_set, test_set = featuresets[size:], featuresets[:size]
classifier = nltk.DecisionTreeClassifier.train(train_set)
print nltk.classify.accuracy(classifier, test_set)
print classifier.classify(pos_features('cats'))
# 输出树的层级
print classifier.pseudocode(depth=4)
 endswith(,) == True: return ','
if endswith(,) == False:
if endswith(the) == True: return 'AT'
if endswith(the) == False:
if endswith(s) == True:
if endswith(is) == True: return 'BEZ'
if endswith(is) == False: return 'VBZ'
if endswith(s) == False:
if endswith(.) == True: return '.'
if endswith(.) == False: return 'NN'
在这里，我们可以看到分类器一开始检查一个词是否以逗号结尾——如果是，它会得到
一个特别的标记“,”。接下来，分类器检查词是否以“the”结尾，这种情况它几乎肯定是
一个限定词。这个“后缀”被决策树早早使用是因为词 the 太常见。分类器继续检查词是否
以 s 结尾，如果是，那么它极有可能得到动词标记 VBZ（除非它是这个词 is，它有特殊标
记 BEZ），如果不是，那么它往往是名词（除非它是标点符号“.”）。实际的分类器包含这里
显示的 if-then 语句下面进一步的嵌套，参数 depth=4 只显示决定树的顶端部分。

"""
为了捕捉相关的分类任务之间的依赖关系，我们可以使用联合分类器模型，收集有关输
入，选择适当的标签。在词性标注的例子中，各种不同的序列分类器模型可以被用来为一个
给定的句子中的所有的词共同选择词性标签。
一种序列分类器策略，称为连续分类或贪婪序列分类，是为第一个输入找到最有可能的
类标签，然后使用这个问题的答案帮助找到下一个输入的最佳的标签。这个过程可以不断重
复直到所有的输入都被贴上标签。这是被 5.5 节的 bigram 标注器采用的方法，它一开始为
215
句子的第一个词选择词性标记，然后为每个随后的词选择标记，基于词本身和前面词的预测
的标记。
在例 6-5 演示了这一策略。首先，我们必须扩展我们的特征提取函数使其具有参数 his
tory，它提供一个我们到目前为止已经为句子预测的标记的链表�。history 中的每个标记
对应句子中的一个词。但是请注意，history 将只包含我们已经归类的词的标记，也就是目
标词左侧的词。因此，虽然是有可能查看目标词右边的词的某些特征，但查看那些词的标记
是不可能的（因为我们还未产生它们）。
已经定义了特征提取器，我们可以继续建立我们的序列分类器�。在训练中，我们使用
已标注的标记为征提取器提供适当的历史信息，但标注新的句子时，我们基于标注器本身的
输出产生历史信息。
例 6-5. 使用连续分类器进行词性标注。
"""





